"""
ordersDF:
order_id (integer)
customer_id (integer)
order_date (date)
order_status (string)

orderItemsDF:
order_item_id (integer)
order_id (integer)
product_id (integer)
quantity (integer)
unit_price (double)

Write a PySpark code to find the total revenue generated by each customer, considering only the orders with
'COMPLETE' status. Also, include customers who have not placed any orders with 'COMPLETE' status, showing their total
revenue as 0. """

from pyspark.sql import SparkSession
from pyspark.sql.functions import when, col, sum, lit
from pyspark.sql.functions import count

order_data = [
    (1, 101, '2023-01-01', 'COMPLETE'),
    (2, 102, '2023-01-02', 'PENDING'),
    (3, 103, '2023-01-03', 'COMPLETE'),
    (4, 101, '2023-01-04', 'COMPLETE'),
    (5, 102, '2023-01-05', 'PENDING')
]

order_items_data = [
    (101, 1, 1, 2, 50.0),
    (102, 1, 1, 2, 30.0),
    (103, 1, 1, 2, 50.0),
    (104, 2, 3, 4, 50.0),
    (105, 3, 1, 1, 40.0),
    (106, 3, 1, 2, 30.0),
    (107, 4, 3, 1, 25.0)
]

spark = SparkSession.builder.appName("Interview Question").getOrCreate()

ordersDF = spark.createDataFrame(order_data, ["order_id", "customer_id", "order_date", "order_status"])

order_items_data_df = spark.createDataFrame(order_items_data,
                                            ["order_item_id", "order_id", "product_id", "quantity", "unit_price"])

ordersDF.show()

order_items_data_df.show()

result_df = ordersDF.join(order_items_data_df,
                          ordersDF.order_id == order_items_data_df.order_id, "left_outer") \
    .groupby("customer_id") \
    .agg(sum(when(col("order_status") == "COMPLETE", col("quantity") * col("unit_price"))
             .otherwise(lit(0))).alias("Revenue"))

result_df.show()
